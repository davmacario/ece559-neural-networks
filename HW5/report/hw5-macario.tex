\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{hyperref}   % Change color and style of \ref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
}

\usepackage{graphicx} % Allows you to insert figures
\graphicspath{ {./images/} } % images are found in this position
\counterwithin{figure}{section} % Settings for figure numbering
\counterwithin{figure}{subsection}

\usepackage{amsmath} % Allows you to do equations
\usepackage{amsfonts} % Contains math. symbols fonts (e.g., 'real numbers' set)
\usepackage{fancyhdr} % Formats the header
\usepackage{geometry} % Formats the paper size, orientation, and margins
\linespread{1.25} % about 1.5 spacing in Word
\setlength{\parindent}{0pt} % no paragraph indents
\setlength{\parskip}{1em} % paragraphs separated by one line

\usepackage{enumitem} % Used to reduce whitespace between list elements
\setlist[itemize]{noitemsep, topsep=0pt} % Set the whitespace above list to the minimum

\usepackage{algorithm}
\usepackage{algpseudocodex}

\usepackage[style=authoryear-ibid,backend=biber,maxbibnames=99,maxcitenames=2,uniquelist=false,isbn=false,url=true,eprint=false,doi=true,giveninits=true,uniquename=init]{biblatex} % Allows you to do citations - does Harvard style and compatible with Zotero
\urlstyle{same} % makes a nicer URL and DOI font
\AtEveryBibitem{
    \clearfield{urlyear}
    \clearfield{urlmonth}
} % removes access date
\AtEveryBibitem{\clearfield{month}} % removes months in bibliography
\AtEveryCitekey{\clearfield{month}} % removes months in citations
\renewbibmacro{in:}{} % Removes the 'In' before journal names

\renewbibmacro*{editorstrg}{%from biblatex.def
  \printtext[editortype]{%
    \iffieldundef{editortype}
      {\ifboolexpr{
        test {\ifnumgreater{\value{editor}}{1}}
        or
        test {\ifandothers{editor}}
        }
        {\bibcpstring{editors}}
        {\bibcpstring{editor}}}
    {\ifbibxstring{\thefield{editortype}}
        {\ifboolexpr{
            test {\ifnumgreater{\value{editor}}{1}}
            or
            test {\ifandothers{editor}}
            }
            {\bibcpstring{\thefield{editortype}s}}%changed
          {\bibcpstring{\thefield{editortype}}}}%changed
        {\thefield{editortype}}}}}

\renewbibmacro*{byeditor+others}{%from biblatex.def
  \ifnameundef{editor}
    {}
    {\printnames[byeditor]{editor}%
     \addspace%added
     \mkbibparens{\usebibmacro{editorstrg}}%added
     \clearname{editor}%
     \newunit}%
  \usebibmacro{byeditorx}%
  \usebibmacro{bytranslator+others}}
  % The commands above from lines 20-49 change the way editors are displayed in books
\AtEveryBibitem{%
  \clearlist{language}%
} % removes language from bibliography
% Removes ibids (ibidems)
\DeclareNameAlias{sortname}{family-given} % Ensures the names of the authors after the first author are in the correct order in the bibliography
\renewcommand*{\revsdnamepunct}{} % Corrects punctuation for authors with just a first initial
%\addbibresource{Example.bib} % Tells LaTeX where the citations are coming from. This is imported from Zotero
\usepackage[format=plain,
            font=it]{caption} % Italicizes figure captions
\usepackage[english]{babel}
\usepackage{csquotes}
\renewcommand*{\nameyeardelim}{\addcomma\space} % Adds comma in in-text citations
\renewcommand{\headrulewidth}{0pt}
\geometry{letterpaper, portrait, margin=1in}
\setlength{\headheight}{14.49998pt}

\newcommand\titleofdoc{Homework 5 – PyTorch} %%%%% Title
\newcommand\GroupName{Davide Macario}
\newcommand\CurrDate{October 26\textsuperscript{th} 2023}

\begin{document}
\begin{titlepage}
   \begin{center}
        \vspace*{4cm} % Adjust spacings to ensure the title page is generally filled with text

        \Huge{\titleofdoc}

        \vspace{0.5cm}
        \LARGE{ECE 559 – Neural Networks}

        \vspace{3 cm}
        \Large{\GroupName\\ }
        \large{UIN:\@ 660603047}


        \vspace{2 cm} % Optional additional info here


        \vspace{3 cm}
        \Large{\CurrDate}

        \vspace{0.25 cm}
        \Large{Fall 2023}


        \vfill
    \end{center}
\end{titlepage}

\setcounter{page}{2}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{\GroupName; \titleofdoc}

% Text here

\section{Introduction}

This homework activity revolves around the implementation of a neural network (NN) in Python using the PyTorch framework.
The task is the classification of a data set of images of 9 different classes of shapes: Circle, Square, Octagon, Heptagon, Nonagon, Star, Hexagon, Pentagon, Triangle.
The data set consists of 10000 PNG images per class, split in 8000 training and 2000 test samples.

\section{Network implementation}

The network needs to be able to accept as input a $200 \prod 200$ 3-channel (R, G, B) image and return as output anine-dimensional vector.
The resulting class is decided as the one whose corresponding output has the highest value among all.

\subsection{Network structure}

This section reports the structure of the used neural network.

\begin{itemize}
  \item The 1\textsuperscript{st} layer is a max-pooling layer with a $4 \prod 4$ kernel and stride length equal to $4$. This achieves a decimation of the image by a factor $4$, making training easier.
  \item The 2\textsuperscript{nd} layer is a convolutional one, with $5 \prod 5$ kernel and unitary stride length, taking as input the three color channels and returning $20$ feature maps (each of size $46 \prod 46$). This layer uses the ReLU activation function.
  \item The 3\textsuperscript{rd} layer is a max-pooling layer with $2 \prod 2$ kernel and stride equal to 2, which halves the spatial dimensions of the feature maps, making them $23 \prod 23$.
  \item The 4\textsuperscript{th} layer is convolutional, producing $50$ feature maps through $5 \prod 5$ kernels moving with unitary stride and yielding $21 \prod 21$ output maps. The activation function is ReLU\@.
  \item The 5\textsuperscript{th} layer is identical to the 3\textsuperscript{rd} one, and makes the feature maps $10 \prod 10$.
  \item The 6\textsuperscript{th} layer is convolutional with $3 \prod 3$ kernel and unit stride, and produces $70$ $8 \prod 8$ feature maps from the $50$ accepted as input.
  \item The 7\textsuperscript{th} layer is again a max pooling layer that halves the spatial dimensions, as the third and fifth. The output consists of $70$ $4 \prod 4$ feature maps.
  \item The 8\textsuperscript{th} layer is a fully-connected one, accepting $1120 = 70 \cdot 4 \cdot 4$ inputs and producing $120$ outputs. Due to the high number of inputs, dropout was performed on this layer, to prevent overfitting caused by weight co-adaptation.
  \item The 9\textsuperscript{th} layer is fully connected, with $120$ inputs and $60$ outputs.
  \item The 10\textsuperscript{th} layer is the output one and it is a fully connected layer accepting $60$ inputs and yielding $9$ outputs (one for each class).
\end{itemize}




\end{document}